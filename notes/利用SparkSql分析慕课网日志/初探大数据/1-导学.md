## 大数据任职要求
 - 属性**Linux**操作系统，熟悉**Linux Shell**编程
 - 熟悉**java**或者**scala语言**，具有一年以上实际开发经验
 - 熟悉**spark sql**或**spark streaming**或**spark code**等编程，具有实际开发经验
 - 熟悉**Hadoop**生态系统或者分布式存储与计算技术
 - 具有良好的开发习惯
 - 思维敏捷、学习能力强、具有良好的逻辑分析能力
 
---
 
## 快速突破口
  - 掌握**Hadoop**、**Hive**的基本使用 
  - 重点突击**Spark**
  - 明确**DataFrame/Dataset**在整个**Spark**框架中的核心地位
  
---

## 课程安排
- **Hadoop**部分
  - 大数据概述
  - 零基础学习**Hadoop**框架三大核心组件的使用
  - **Hive**快速入门及使用
- **Spark SQL**部分
  - 认知**Spark**及生态圈
  - 零基础搭建**Spark**环境(源码编译、Spark部署)
  - Spark SQL概述
  - 如何从Hive平滑的过度到SparkSQL
  - DataDrame&Dataset操作详解
  - 外部数据源详解
  - Spark SQL的愿景深度剖析
  - 慕课网日志分析项目实战
  - Spark SQL务必要掌握的N件事情
  
---

## 前置基础知识要求  
- 熟悉基本SQL的使用
- 熟悉常用Linux命令的使用
- 熟悉一门编程语言(Java/**Scala**/Python)均可

---

## 选择Scala作为开发语言的原因
- Spark内核源码是采用Scala开发的
- Scala相对于Java开发更加的优雅和方便
- 主站上有Scala基础课程的视频
  - http://www.imooc.com/learn/613
  
---
## 环境参数
- Linux版本 : CentOS(6.4)
- Hadoop版本 : CDH(hadoop-2.6.0-cdh5.7.0)
- Hive版本 : CDH(hive-1.1.0-cdh5.7.0)
- Scala版本 : 2.11.8
- Spark版本 : spark-2.1.0
- 开发工具 : IDEA
